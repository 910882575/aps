# APS

[![License](https://img.shields.io/badge/License-Apache%202.0-brightgreen.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python-Version](https://img.shields.io/badge/Python-3.7%7C3.8-brightgreen)](https://github.com/funcwj/aps)
[![Testing](https://github.com/funcwj/aps/workflows/Unit%20Testing/badge.svg)](https://github.com/funcwj/aps/workflows/Unit%20Testing/badge.svg)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)


A workspace for speech related tasks, including single/multi-channel speech enhancement & separation & recognition. The goal is to make it easy and flexible to do experiments, verify ideas, implement and evaluate neural networks based methods.

## Setup

```shell
git clone https://github.com/funcwj/aps
# set up the python environments or create conda enviroments based on requirements.txt (recommend)
cd aps && pip install -r requirements.txt
# set up the git hook scripts
pre-commit install
```

## Introduction

* [Overivew](doc/overview.md)
* [Structure](doc/code.md)
* [Instruction](doc/instruction.md)
* [Q & A](doc/QApart.md)
* [Examples](examples)

## Acknowledge

The project was started at 2019.03 when the author was a master student of the Audio, Speech and Language Processing Group (ASLP) in Northwestern Polytechnical University (NWPU), Xi'an, China.
